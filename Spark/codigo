#Conexión a la shell de scala
/opt/spark-1.6.2/bin/spark-shell --packages JMailloH:kNN_IS:3.0,sramirez:spark-infotheoretic-feature-selection:1.3.1,sramirez:spark-MDLP-discretization:1.2.1

//Importación de las librerías
import org.apache.spark.SparkContext
import org.apache.spark.SparkConf
import org.apache.spark.rdd._
import org.apache.spark.mllib.linalg.Vectors
import org.apache.spark.mllib.regression.LabeledPoint
import org.apache.spark.mllib.evaluation.MulticlassMetrics
import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics
import org.apache.spark.mllib.classification.kNN_IS.kNN_IS
import utils.keel.KeelParser
import scala.collection.mutable.ListBuffer

//Carga de los datasets
val converter = new KeelParser(sc, "hdfs://hadoop-master/user/spark/datasets/ECBDL14_mbd/ecbdl14.header")
val train = sc.textFile("hdfs://hadoop-master/user/spark/datasets/ECBDL14_mbd/ecbdl14tra.data", 6).map(line => converter.parserToLabeledPoint(line)).coalesce(6).cache()
train.count()
//Obteniendo una longitud de 499449 instancias
val test = sc.textFile("hdfs://hadoop-master/user/spark/datasets/ECBDL14_mbd/ecbdl14tst.data", 6).map(line => converter.parserToLabeledPoint(line)).cache()
test.count()
//Obteniendo una longitud de 412636 instancias


//RANDOM FOREST
import org.apache.spark.mllib.tree.RandomForest
import org.apache.spark.mllib.tree.model.RandomForestModel
import org.apache.spark.mllib.util.MLUtils
//Configuramos el modelo y lo entrenamos
val numClasses = 2
val categoricalFeaturesInfo = Map[Int, Int]()
val numTrees = 10 
val featureSubsetStrategy = "auto" 
val impurity = "gini"
val maxDepth = 4
val maxBins = 32
val model = RandomForest.trainClassifier(train, numClasses, categoricalFeaturesInfo,
  numTrees, featureSubsetStrategy, impurity, maxDepth, maxBins)
//Evaluamos el modelo con el test
val predsAndLabels = test.map { point =>
  val prediction = model.predict(point.features)
  (prediction, point.label)
}
//Obtenemos el test error
val testErr_rf1 = predsAndLabels.filter(r => r._1 != r._2).count.toDouble / test.count() 
println("Test Error rf1 = " + testErr_rf1) //0.2943
println("Learned model:\n" + model.toDebugString) //Mostramos el modelo

//Mostramos los resultados pormenorizados
import org.apache.spark.mllib.evaluation._
val metrics_rf1 = new MulticlassMetrics(predsAndLabels)
metrics_rf1.precision //0.70567
metrics_rf1.confusionMatrix 
// 268239.0  6852.0   
// 114598.0  22947.0  
val binaryMetrics_rf1 = new BinaryClassificationMetrics(predsAndLabels)
val area_under_ROC_rf1 = binaryMetrics_rf1.areaUnderROC //0.57096
println("Area under ROC = " + area_under_ROC_rf1)


//NAIVE BAYES
import org.apache.spark.mllib.classification.{NaiveBayes, NaiveBayesModel}
import org.apache.spark.mllib.linalg.Vectors
//Creamos el modelo
val model = NaiveBayes.train(train, lambda = 1.0, modelType = "multinomial")
//Evaluamos el modelo
val predsAndLabels = test.map { point =>
  val prediction = model.predict(point.features)
  (prediction, point.label)
}
//Obtenemos el test error
val testErr_nb1 = predsAndLabels.filter(r => r._1 != r._2).count.toDouble / test.count()
println("Test Error = " + testErr_nb1) //0.29375

//Mostramos los resultados pormenorizados
import org.apache.spark.mllib.evaluation._
val metrics_nb1 = new MulticlassMetrics(predsAndLabels)
metrics_nb1.precision //0.70625
metrics_nb1.confusionMatrix 
// 248743.0  26348.0  
// 94863.0   42682.0  
val binaryMetrics_nb1 = new BinaryClassificationMetrics(predsAndLabels)
val area_under_ROC_nb1 = binaryMetrics_nb1.areaUnderROC //0.60727
println("Area under ROC = " + area_under_ROC_nb1)


//DECISION TREES
import org.apache.spark.mllib.tree.DecisionTree
import org.apache.spark.mllib.tree.model.DecisionTreeModel
import org.apache.spark.mllib.util.MLUtils
//Configuramos el modelo y lo entrenamos
val numClasses = 2
val categoricalFeaturesInfo = Map[Int, Int]()
val impurity = "gini"
val maxDepth = 4
val maxBins = 32
val model = DecisionTree.trainClassifier(train, numClasses, categoricalFeaturesInfo,
  impurity, maxDepth, maxBins)
//Evaluamos el modelo con el test
val predsAndLabels = test.map { point =>
  val prediction = model.predict(point.features)
  (prediction, point.label)
}
//Obtenemos el test error
val testErr_dt1 = predsAndLabels.filter(r => r._1 != r._2).count.toDouble / test.count() 
println("Test Error = " + testErr_dt1) //0.27039
println("Learned model:\n" + model.toDebugString) //Mostramos el modelo

//Mostramos los resultados pormenorizados
import org.apache.spark.mllib.evaluation._
val metrics_dt1 = new MulticlassMetrics(predsAndLabels)
metrics_dt1.precision //0.72961
metrics_dt1.confusionMatrix 
// 233359.0  41732.0  
// 69840.0   67705.0  
val binaryMetrics_dt1 = new BinaryClassificationMetrics(predsAndLabels)
val area_under_ROC_dt1 = binaryMetrics_dt1.areaUnderROC //0.67027
println("Area under ROC = " + area_under_ROC_dt1)


//DISCRETIZACIÓN DE LOS DATOS
import org.apache.spark.mllib.feature.MDLPDiscretizer
val categoricalFeat: Option[Seq[Int]] = None
val nBins = 15
val maxByPart = 10000
println("*** Discretization method: Fayyad discretizer (MDLP)")
println("*** Number of bins: " + nBins) //15 bins
//Los datos deben almacenarse en cache para mejorar el rendimiento
val discretizer = MDLPDiscretizer.train(train, // RDD[LabeledPoint]
    categoricalFeat, // continuous features
    nBins, // max number of thresholds by feature
    maxByPart) // max elements per partition
discretizer
//Discretizamos el train
val discreteTrain = train.map(i => LabeledPoint(i.label, discretizer.transform(i.features))).cache()
discreteTrain.count() //499449
discreteTrain.first()
//Discretizamos el test
val discreteTest = test.map(i => LabeledPoint(i.label, discretizer.transform(i.features))).cache()
discreteTest.count() //412636


//SELECCIÓN DE CARACTERÍSTICAS SOBRE LOS DATOS DISCRETIZADOS
import org.apache.spark.mllib.feature._
val criterion = new InfoThCriterionFactory("mrmr")
val nToSelect = 10
val nPartitions = 6
println("*** FS criterion: " + criterion.getCriterion.toString)
println("*** Number of features to select: " + nToSelect)
println("*** Number of partitions: " + nPartitions)
//Discretizamos con 6 particiones y 10 características
val featureSelector = new InfoThSelector(criterion, nToSelect, nPartitions).fit(discreteTrain)
//Obtenemos que:
//Feature	Score
//1	0.0762
//2	0.0275
//6	0.0065
//72	0.0043
//275	0.0001
//366	-0.0000
//16	0.0012
//591	-0.0000
//611	-0.0000
//354	-0.0000
val reducedTrain10 = discreteTrain.map(i => LabeledPoint(i.label, featureSelector.transform(i.features))).cache()
reducedTrain10.count()
//Ahora el test
val reducedTest10 = discreteTrain.map(i => LabeledPoint(i.label, featureSelector.transform(i.features))).cache()
reducedTest10.count()


//RANDOM FOREST CON SELECCIÓN DE CARACTERÍSTICAS
//Entrenamos el modelo sobre el conjunto de datos reducido
val model = RandomForest.trainClassifier(reducedTrain10, numClasses, categoricalFeaturesInfo,
  numTrees, featureSubsetStrategy, impurity, maxDepth, maxBins)
//Evaluamos el modelo 
val predsAndLabels = reducedTest10.map { point =>
  val prediction = model.predict(point.features)
  (prediction, point.label)
}
val testErr_rf2 = predsAndLabels.filter(r => r._1 != r._2).count.toDouble / reducedTest10.count()
println("Test Error = " + testErr_rf2) //0.27438
println("Learned model:\n" + model.toDebugString)

//Mostramos los resultados pormenorizados
val metrics_rf2 = new MulticlassMetrics(predsAndLabels)
metrics_rf2.precision //0.72562
metrics_rf2.confusionMatrix 
// 328806.0  20466.0  
// 116573.0  33604.0   
val binaryMetrics_rf2 = new BinaryClassificationMetrics(predsAndLabels)
val area_under_ROC_rf2 = binaryMetrics_rf2.areaUnderROC //0.58258
println("Area Under ROC = " + area_under_ROC_rf2)

//NAIVE BAYES CON SELECCIÓN DE CARACTERÍSTICAS
val model = NaiveBayes.train(reducedTrain10, lambda = 1.0, modelType = "multinomial")
// Evaluamos
val predsAndLabels = reducedTest10.map { point =>
  val prediction = model.predict(point.features)
  (prediction, point.label)
}
val testErr_nb2 = predsAndLabels.filter(r => r._1 != r._2).count.toDouble / reducedTest10.count()
println("Test Error = " + testErr_nb2) //0.28493

//Mostramos los resultados pormenorizados
val metrics_nb2 = new MulticlassMetrics(predsAndLabels)
metrics_nb2.precision //0.71506
metrics_nb2.confusionMatrix 
// 282793.0  66479.0  
// 75831.0   74346.0 
val binaryMetrics_nb2 = new BinaryClassificationMetrics(predsAndLabels)
val area_under_ROC_nb2 = binaryMetrics_nb2.areaUnderROC //0.65236
println("Area Under ROC = " + area_under_ROC_nb2)


//DECISION TREES CON SELECCIÓN DE CARACTERÍSTICAS
//Entrenamos el modelo sobre el conjunto de datos reducido
val model = DecisionTree.trainClassifier(reducedTrain10, numClasses, categoricalFeaturesInfo,
  impurity, maxDepth, maxBins)
//Evaluamos el modelo 
val predsAndLabels = reducedTest10.map { point =>
  val prediction = model.predict(point.features)
  (prediction, point.label)
}
val testErr_dt2 = predsAndLabels.filter(r => r._1 != r._2).count.toDouble / reducedTest10.count()
println("Test Error = " + testErr_dt2) //0.27189
println("Learned model:\n" + model.toDebugString)

//Mostramos los resultados pormenorizados
val metrics_dt2 = new MulticlassMetrics(predsAndLabels)
metrics_dt2.precision //0.72810
metrics_dt2.confusionMatrix 
// 311743.0  37529.0  
// 98270.0   51907.0  
val binaryMetrics_dt2 = new BinaryClassificationMetrics(predsAndLabels)
val area_under_ROC_dt2 = binaryMetrics_dt2.areaUnderROC //0.61909
println("Area Under ROC = " + area_under_ROC_dt2)

















println("RANDOM FOREST RF1")
println("Test Error rf1 = " + testErr_rf1) //0.
println("Precision rf1 = " + metrics_rf1.precision) //0.
println("Confusion Matrix rf1 = " + metrics_rf1.confusionMatrix) //0.
println("Area Under ROC rf1 = " + area_under_ROC_rf1) //0.

println("NAIVE BAYES NB1")
println("Test Error nb1 = " + testErr_nb1) //0.
println("Precision nb1 = " + metrics_nb1.precision) //0.
println("Confusion Matrix nb1 = " + metrics_nb1.confusionMatrix) //0.
println("Area Under ROC nb1 = " + area_under_ROC_nb1) //0.

println("DECISION TREE DT1")
println("Test Error dt1 = " + testErr_dt1) //0.
println("Precision dt1 = " + metrics_dt1.precision) //0.
println("Confusion Matrix dt1 = " + metrics_dt1.confusionMatrix) //0.
println("Area Under ROC dt1 = " + area_under_ROC_dt1) //0.


println("RANDOM FOREST RF2")
println("Test Error rf2 = " + testErr_rf2) //0.
println("Precision rf2 = " + metrics_rf2.precision) //0.
println("Confusion Matrix rf2 = " + metrics_rf2.confusionMatrix) //0.
println("Area Under ROC rf2 = " + area_under_ROC_rf2) //0.

println("NAIVE BAYES NB2")
println("Test Error nb2 = " + testErr_nb2) //0.
println("Precision nb2 = " + metrics_nb2.precision) //0.
println("Confusion Matrix nb2 = " + metrics_nb2.confusionMatrix) //0.
println("Area Under ROC nb2 = " + area_under_ROC_nb2) //0.

println("DECISION TREE DT2")
println("Test Error dt2 = " + testErr_dt2) //0.
println("Precision dt2 = " + metrics_dt2.precision) //0.
println("Confusion Matrix dt2 = " + metrics_dt2.confusionMatrix) //0.
println("Area Under ROC dt2 = " + area_under_ROC_dt2) //0.



